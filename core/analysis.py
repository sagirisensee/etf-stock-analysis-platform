import asyncio
import logging
import random
import time
import pandas as pd
from .data_fetcher import (
    get_all_etf_spot_realtime,
    get_etf_daily_history,
    get_etf_minute_history,
    get_all_stock_spot_realtime,
    get_stock_daily_history,
    get_stock_minute_history,
)
from .llm_analyzer import get_llm_score_and_analysis
from .llm_analyzer import extract_signal_from_comment
from .indicators import analyze_ma, analyze_macd, analyze_bollinger
from .indicators import (
    analyze_rsi,
    analyze_kdj,
    analyze_cci,
    analyze_obv,
    analyze_williams,
)
from .indicators import calculate_forward_indicators
from .indicators import calculate_minute_indicators
from .indicators import calculate_minute_support_resistance
from .indicators import calculate_entry_signals
from .indicators import judge_trend_status
from .indicators import calculate_macd_for_eastmoney
from .signal_system import SignalSystem
from .alert_system import AlertSystem

logger = logging.getLogger(__name__)
pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)


def _create_realtime_data_from_history(daily_trends_list, core_pool):
    """
    å½“å®æ—¶æ•°æ®è·å–å¤±è´¥æ—¶ï¼Œä½¿ç”¨å†å²æ•°æ®çš„æœ€æ–°ä»·æ ¼åˆ›å»ºå®æ—¶æ•°æ®
    """
    try:
        logger.info("ğŸ”„ æ­£åœ¨ä»å†å²æ•°æ®åˆ›å»ºå®æ—¶æ•°æ®...")

        realtime_data = []
        for item in core_pool:
            code = item["code"]
            name = item["name"]
            item_type = item.get("type", "stock")  # è·å–æ ‡çš„ç±»å‹

            # æŸ¥æ‰¾å¯¹åº”çš„å†å²æ•°æ®
            history_data = None
            for trend in daily_trends_list:
                if trend["code"] == code:
                    history_data = trend.get("raw_debug_data", {}).get("history_data")
                    break

            if history_data is not None and not history_data.empty:
                # ä½¿ç”¨æœ€æ–°ä¸€å¤©çš„æ•°æ®ä½œä¸ºå®æ—¶æ•°æ®
                latest = history_data.iloc[-1]

                # æ¶¨è·Œå¹…ç»Ÿä¸€å¤„ç†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
                change_pct = latest.get("æ¶¨è·Œå¹…", 0)

                realtime_data.append(
                    {
                        "ä»£ç ": code,
                        "åç§°": name,
                        "æœ€æ–°ä»·": latest.get("close", 0),
                        "æ¶¨è·Œå¹…": change_pct,
                        "æ¶¨è·Œé¢": latest.get("æ¶¨è·Œé¢", 0),
                        "æ˜¨æ”¶": latest.get("close", 0),  # ä½¿ç”¨æ”¶ç›˜ä»·ä½œä¸ºæ˜¨æ”¶
                    }
                )
                logger.info(
                    f"âœ… ä»å†å²æ•°æ®åˆ›å»ºå®æ—¶æ•°æ®: {name}({code}) - ä»·æ ¼: {latest.get('close', 0)}"
                )
            else:
                logger.warning(f"âš ï¸ æ— æ³•æ‰¾åˆ° {name}({code}) çš„å†å²æ•°æ®")

        if realtime_data:
            df = pd.DataFrame(realtime_data)
            logger.info(f"âœ… æˆåŠŸåˆ›å»ºå®æ—¶æ•°æ®ï¼ŒåŒ…å« {len(df)} ä¸ªæ ‡çš„")
            return df
        else:
            logger.error("âŒ æ— æ³•ä»å†å²æ•°æ®åˆ›å»ºä»»ä½•å®æ—¶æ•°æ®")
            return None

    except Exception as e:
        logger.error(f"âŒ ä»å†å²æ•°æ®åˆ›å»ºå®æ—¶æ•°æ®å¤±è´¥: {e}", exc_info=True)
        return None


async def generate_ai_driven_report(
    get_realtime_data_func, get_daily_history_func, core_pool
):
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„ç»Ÿä¸€å…¨é¢åˆ†æå¼•æ“...")
    final_report = []
    start_time = time.time()
    MAX_ANALYSIS_TIME = 600  # 10åˆ†é’Ÿè¶…æ—¶

    try:
        # å¹¶è¡Œè·å–å®æ—¶æ•°æ®å’Œå†å²æ•°æ®ï¼Œæ·»åŠ è¶…æ—¶æ§åˆ¶
        realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
        daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)

        try:
            # è®¾ç½®è¶…æ—¶ï¼š10åˆ†é’Ÿ
            realtime_data_df, daily_trends_list = await asyncio.wait_for(
                asyncio.gather(
                    realtime_data_df_task, daily_trends_task, return_exceptions=True
                ),
                timeout=MAX_ANALYSIS_TIME,
            )
        except asyncio.TimeoutError:
            logger.error(f"åˆ†æè¶…æ—¶ï¼ˆè¶…è¿‡{MAX_ANALYSIS_TIME}ç§’ï¼‰ï¼Œåœæ­¢åˆ†æ")
            # è¶…æ—¶æ—¶ï¼Œåªè¿”å›å·²å¤„ç†çš„æ ‡çš„ï¼Œä¸è¿”å›é”™è¯¯æŠ¥å‘Š
            return final_report if final_report else []
        except Exception as e:
            logger.error(f"æ•°æ®è·å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            # å¦‚æœæ•°æ®è·å–å¤±è´¥ï¼Œä¸è¿”å›é”™è¯¯æŠ¥å‘Šï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨
            return []

        # å¤„ç†å®æ—¶æ•°æ®è·å–ç»“æœ
        if isinstance(realtime_data_df, Exception):
            logger.error(f"å®æ—¶æ•°æ®è·å–å¤±è´¥: {realtime_data_df}")
            realtime_data_df = None
        elif realtime_data_df is None:
            logger.warning("å®æ—¶æ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†å²æ•°æ®ä½œä¸ºæ›¿ä»£")

        # å¤„ç†å†å²æ•°æ®è·å–ç»“æœ
        if isinstance(daily_trends_list, Exception):
            logger.error(f"å†å²æ•°æ®è·å–å¤±è´¥: {daily_trends_list}")
            daily_trends_list = []
        elif daily_trends_list is None:
            logger.warning("å†å²æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨")
            daily_trends_list = []

        # å¦‚æœå®æ—¶æ•°æ®ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨å†å²æ•°æ®åˆ›å»º
        if realtime_data_df is None or (
            isinstance(realtime_data_df, pd.DataFrame) and realtime_data_df.empty
        ):
            logger.warning("å®æ—¶æ•°æ®ä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨å†å²æ•°æ®åˆ›å»º")
            realtime_data_df = _create_realtime_data_from_history(
                daily_trends_list, core_pool
            )
            if realtime_data_df is None or (
                isinstance(realtime_data_df, pd.DataFrame) and realtime_data_df.empty
            ):
                logger.error(
                    "æ— æ³•è·å–å®æ—¶æ•°æ®ï¼Œä¹Ÿæ— æ³•ä»å†å²æ•°æ®åˆ›å»ºï¼Œå°†ä½¿ç”¨ç©ºDataFrameç»§ç»­åˆ†æ"
                )
                # åˆ›å»ºç©ºDataFrameï¼Œä½†ç¡®ä¿æœ‰æ­£ç¡®çš„åˆ—ç»“æ„
                realtime_data_df = pd.DataFrame(
                    columns=["ä»£ç ", "åç§°", "æœ€æ–°ä»·", "æ¶¨è·Œå¹…"]
                )

        daily_trends_map = {item["code"]: item for item in daily_trends_list}

        # æ ¹æ®core_poolä¸­çš„typeå­—æ®µåˆ¤æ–­ï¼Œè€Œä¸æ˜¯æ ¹æ®å‡½æ•°å¼•ç”¨
        if core_pool and core_pool[0].get("type") == "stock":
            item_type = "stock"
        else:
            item_type = "etf"

        # ç”Ÿæˆæ—¥å†…ä¿¡å·
        try:
            intraday_analyzer = _IntradaySignalGenerator(core_pool, item_type=item_type)
            intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ—¥å†…ä¿¡å·æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            # å¦‚æœä¿¡å·ç”Ÿæˆå¤±è´¥ï¼Œä¸ºæ¯ä¸ªæ ‡çš„åˆ›å»ºåŸºç¡€ä¿¡å·
            intraday_signals = []
            for item in core_pool:
                intraday_signals.append(
                    {
                        "code": item.get("code", ""),
                        "name": item.get("name", "æœªçŸ¥"),
                        "price": None,
                        "change": 0,
                        "æ¶¨è·Œå¹…": 0,
                        "analysis_points": [f"ä¿¡å·ç”Ÿæˆå¤±è´¥: {str(e)}"],
                    }
                )

        # å¤„ç†æ¯ä¸ªæ ‡çš„çš„åˆ†æ
        for i, signal in enumerate(intraday_signals):
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            elapsed_time = time.time() - start_time
            if elapsed_time > MAX_ANALYSIS_TIME:
                logger.warning(
                    f"åˆ†æè¶…æ—¶ï¼ˆå·²ç”¨æ—¶ {elapsed_time:.1f}ç§’ï¼‰ï¼Œåœæ­¢å¤„ç†å‰©ä½™æ ‡çš„"
                )
                break

            code = signal.get("code", "")
            name = signal.get("name", "æœªçŸ¥")

            try:
                # è·å–å†å²è¶‹åŠ¿æ•°æ®
                daily_trend = daily_trends_map.get(
                    code,
                    {"status": "ğŸŸ¡ æ•°æ®çŠ¶æ€æœªçŸ¥", "technical_indicators_summary": []},
                )

                # æ£€æŸ¥æ•°æ®æ˜¯å¦å……è¶³ï¼šå¦‚æœçŠ¶æ€æ˜¯æ•°æ®ä¸è¶³æˆ–æ•°æ®ç¼ºå¤±ï¼Œè·³è¿‡ä¸å†™å…¥
                daily_trend_status = daily_trend.get("status", "")
                if not daily_trend_status:
                    daily_trend_status = "ğŸŸ¡ æ•°æ®çŠ¶æ€æœªçŸ¥"

                # ä¸è·³è¿‡æ•°æ®ä¸è¶³çš„æƒ…å†µï¼Œä¼ é€’ç»™LLMåˆ†ææ—¶ä¼šæ ‡è®°æ•°æ®ä¸è¶³çŠ¶æ€

                # æ£€æŸ¥å®æ—¶æ•°æ®æ˜¯å¦æœ‰æ•ˆ
                price = signal.get("price")
                if price is None:
                    logger.info(
                        f"è·³è¿‡ {name}({code})ï¼šå®æ—¶ä»·æ ¼æ•°æ®ç¼ºå¤±ï¼Œä¸å†™å…¥åˆ†æç»“æœ"
                    )
                    continue

                # è·å–å‰ç»æ€§æ•°æ®
                forward_indicators = daily_trend.get("raw_debug_data", {}).get(
                    "forward_indicators", {}
                )
                signal_data = daily_trend.get("signal_data", {})
                alert_data = daily_trend.get("alert_data", {})
                # prediction_dataä¸å†ä½¿ç”¨ï¼Œå®Œå…¨ä¾èµ–AIé¢„æµ‹
                prediction_data = {}

                # è·å–å½“å‰ä»·æ ¼ï¼ˆç”¨äºæ”¯æ’‘é˜»åŠ›è®¡ç®—ï¼‰
                current_price = signal.get("price", 0)

                # è·å–åˆ†é’Ÿçº¿æ•°æ®ï¼ˆä»…å¯¹ETFï¼‰
                minute_30_data = None
                minute_60_data = None
                minute_support_resistance = {}
                minute_entry_signals = {}

                try:
                    if item_type == "etf":
                        # è·å–30åˆ†é’Ÿçº¿æ•°æ®
                        minute_30_data = await asyncio.wait_for(
                            get_etf_minute_history(code, period="30", days=7),
                            timeout=30,
                        )
                        # è·å–60åˆ†é’Ÿçº¿æ•°æ®
                        minute_60_data = await asyncio.wait_for(
                            get_etf_minute_history(code, period="60", days=7),
                            timeout=30,
                        )
                    elif item_type == "stock":
                        # è·å–30åˆ†é’Ÿçº¿æ•°æ®
                        minute_30_data = await asyncio.wait_for(
                            get_stock_minute_history(code, period="30", days=7),
                            timeout=30,
                        )
                        # è·å–60åˆ†é’Ÿçº¿æ•°æ®
                        minute_60_data = await asyncio.wait_for(
                            get_stock_minute_history(code, period="60", days=7),
                            timeout=30,
                        )
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    if minute_30_data is not None and not minute_30_data.empty:
                        minute_30_data = calculate_minute_indicators(
                            minute_30_data, period="30"
                        )
                    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                    if minute_60_data is not None and not minute_60_data.empty:
                        minute_60_data = calculate_minute_indicators(
                            minute_60_data, period="60"
                        )

                    # è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½å’Œå…¥åœºä¿¡å·ï¼ˆéœ€è¦ä¸¤ä¸ªå‘¨æœŸéƒ½æœ‰æ•°æ®ï¼‰
                    if (
                        minute_30_data is not None
                        and not minute_30_data.empty
                        and minute_60_data is not None
                        and not minute_60_data.empty
                    ):
                        minute_support_resistance = calculate_minute_support_resistance(
                            minute_30_data, minute_60_data, current_price
                        )

                        # è®¡ç®—å…¥åœºä¿¡å·
                        minute_entry_signals = calculate_entry_signals(
                            minute_30_data,
                            minute_60_data,
                            minute_support_resistance,
                            current_price,
                        )
                except asyncio.TimeoutError:
                    logger.warning(f"è·å–{name}({code})åˆ†é’Ÿçº¿æ•°æ®è¶…æ—¶")
                except Exception as e:
                    logger.warning(f"è·å–{name}({code})åˆ†é’Ÿçº¿æ•°æ®å¤±è´¥: {e}")

                # è°ƒç”¨LLMåˆ†æï¼ˆä¼ å…¥å¤šå‘¨æœŸæ•°æ®ï¼‰
                try:
                    ai_result = await asyncio.wait_for(
                        get_llm_score_and_analysis(
                            signal,
                            daily_trend,
                            forward_indicators_data=forward_indicators,
                            minute_30_data=minute_30_data,
                            minute_60_data=minute_60_data,
                            minute_support_resistance=minute_support_resistance,
                            minute_entry_signals=minute_entry_signals,
                            signal_data=signal_data,
                            alert_data=alert_data,
                            prediction_data=prediction_data,
                        ),
                        timeout=60,  # LLMåˆ†æå•æ¬¡è¶…æ—¶60ç§’
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"LLMåˆ†æ {name}({code}) è¶…æ—¶ï¼Œè·³è¿‡")
                    continue
                except Exception as e:
                    logger.error(f"LLMåˆ†æ {name}({code}) æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    # LLMåˆ†æå¤±è´¥æ—¶ï¼Œè·³è¿‡ä¸å†™å…¥
                    continue

                # åªæœ‰æ•°æ®å……è¶³æ—¶æ‰å†™å…¥åˆ†æç»“æœ
                # è·å–AIé¢„æµ‹æ•°æ®
                ai_pred_1d = ai_result.get("pred_1d", {})
                ai_pred_3d = ai_result.get("pred_3d", {})

                # ç¡®ä¿AIé¢„æµ‹æ•°æ®åŒ…å«æ•°å€¼ç½®ä¿¡åº¦
                # åªæœ‰å½“AIæ²¡æœ‰è¿”å›ä»»ä½•é¢„æµ‹æ•°æ®æ—¶æ‰è®¾ç½®é»˜è®¤å€¼
                # å¦‚æœAIè¿”å›äº†ç©ºå­—å…¸{}ï¼Œè¡¨ç¤ºAIåˆ†æäº†ä½†æ²¡æœ‰é¢„æµ‹ç»“æœï¼Œåº”è¯¥ä¿ç•™ç©ºå­—å…¸
                if ai_pred_1d is None:
                    ai_pred_1d = {
                        "trend": "åˆ†æä¸­",
                        "target": "è®¡ç®—ä¸­",
                        "confidence": 50,
                    }
                if ai_pred_3d is None:
                    ai_pred_3d = {
                        "trend": "åˆ†æä¸­",
                        "target": "è®¡ç®—ä¸­",
                        "confidence": 50,
                    }

                final_report.append(
                    {
                        **signal,
                        "ai_signal": ai_result.get("signal", "æŒæœ‰"),
                        "ai_confidence": ai_result.get("confidence", 50),
                        "ai_probability": ai_result.get("probability", "æ¶¨è·Œæ¦‚ç‡æœªçŸ¥"),
                        # ç¡®ä¿æœ‰é»˜è®¤å€¼ï¼Œé¿å…å‰ç«¯æ˜¾ç¤º"æ­£åœ¨è®¡ç®—ä¸­..."
                        "ai_detailed_probability": ai_result.get("detailed_probability")
                        or {"up": 35, "down": 45, "sideways": 20},
                        "ai_pred_1d": ai_pred_1d,
                        "ai_pred_3d": ai_pred_3d,
                        "ai_support": ai_result.get("support", "æœªçŸ¥"),
                        "ai_resistance": ai_result.get("resistance", "æœªçŸ¥"),
                        "ai_target": ai_result.get("target", "æœªçŸ¥"),
                        "ai_stop_loss": ai_result.get("stop_loss", "æœªçŸ¥"),
                        "ai_comment": ai_result.get("comment", "AIåˆ†æå®Œæˆ"),
                        "daily_trend_status": daily_trend_status,
                        "technical_indicators_summary": daily_trend.get(
                            "technical_indicators_summary", []
                        ),
                        # æ–°å¢ï¼šå‰ç»æ€§æŒ‡æ ‡æ•°æ®
                        "forward_indicators": forward_indicators,
                        # æ–°å¢ï¼šä¹°å–ä¿¡å·æ•°æ®
                        "signal_data": signal_data,
                        # ä¸åŒ…å«ç®—æ³•é¢„æµ‹æ•°æ®ï¼Œå®Œå…¨ä¾èµ–AIé¢„æµ‹
                        # "prediction_data": prediction_data,
                        # æ–°å¢ï¼šé¢„è­¦æ•°æ®
                        "alert_data": alert_data,
                        # æ ‡è®°ä½¿ç”¨AIé©±åŠ¨çš„æ¦‚ç‡
                        "use_ai_probability": True,
                    }
                )

            except Exception as e:
                logger.error(f"å¤„ç† {name}({code}) åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {e}")
                # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè·³è¿‡ä¸å†™å…¥é”™è¯¯æŠ¥å‘Š
                continue

            # éšæœºå»¶è¿Ÿï¼Œä½†æ£€æŸ¥è¶…æ—¶
            delay = random.uniform(1.0, 2.5)
            if elapsed_time + delay > MAX_ANALYSIS_TIME:
                break
            await asyncio.sleep(delay)

    except Exception as e:
        logger.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
        # å‘ç”Ÿä¸¥é‡é”™è¯¯æ—¶ï¼Œä¸è¿”å›é”™è¯¯æŠ¥å‘Šï¼Œç›´æ¥è¿”å›å·²å¤„ç†çš„ç»“æœ
        return final_report if final_report else []

    # æŒ‰AIè¯„åˆ†æ’åºï¼Œåªè¿”å›æœ‰æ•ˆçš„åˆ†æç»“æœ
    try:
        if not final_report:
            return []
        return sorted(
            final_report,
            key=lambda x: (
                -x.get("ai_score", 0)
                if isinstance(x.get("ai_score"), (int, float))
                else 0
            ),
            reverse=True,
        )
    except Exception as e:
        logger.error(f"æ’åºç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return final_report if final_report else []


async def _get_daily_trends_generic(get_daily_history_func, core_pool):
    analysis_report = []
    start_time = time.time()
    MAX_DATA_FETCH_TIME = 480  # 8åˆ†é’Ÿè¶…æ—¶ï¼ˆç»™åˆ†æç•™å‡ºæ—¶é—´ï¼‰

    # å¼€å§‹è·å–å†å²æ•°æ®
    for i, item_info in enumerate(core_pool):
        # æ£€æŸ¥è¶…æ—¶
        elapsed_time = time.time() - start_time
        if elapsed_time > MAX_DATA_FETCH_TIME:
            logger.warning(
                f"å†å²æ•°æ®è·å–è¶…æ—¶ï¼ˆå·²ç”¨æ—¶ {elapsed_time:.1f}ç§’ï¼‰ï¼Œåœæ­¢è·å–å‰©ä½™æ ‡çš„"
            )
            break

        code = item_info["code"]
        name = item_info["name"]
        item_type = item_info.get("type", "stock")

        try:
            # è°ƒç”¨æ•°æ®è·å–å‡½æ•°ï¼Œæ·»åŠ å•æ¬¡è¶…æ—¶æ§åˆ¶
            try:
                result = await asyncio.wait_for(
                    get_daily_history_func(code, item_type),
                    timeout=120,  # å•ä¸ªæ ‡çš„æ•°æ®è·å–è¶…æ—¶2åˆ†é’Ÿ
                )
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ {name}({code}) å†å²æ•°æ®è·å–è¶…æ—¶ï¼Œè·³è¿‡")
                continue
            except Exception as e:
                logger.error(f"ğŸ’¥ {name}({code}) å†å²æ•°æ®è·å–å¼‚å¸¸: {e}")
                # æ•°æ®è·å–å¤±è´¥æ—¶ï¼Œè·³è¿‡ä¸å†™å…¥
                continue

            # å†å²æ•°æ®è·å–ç»“æœæ£€æŸ¥
            data_insufficient = False
            if result is None or result.empty:
                logger.info(f"âš ï¸ {name}({code})ï¼šå†å²æ•°æ®ä¸è¶³ï¼Œæ ‡è®°ä¸ºæ•°æ®ä¸è¶³")
                data_insufficient = True
                # åˆ›å»ºç©ºçš„æ•°æ®æ¡†ï¼Œä½†æ·»åŠ åŸºæœ¬çŠ¶æ€ä¿¡æ¯
                analysis_report.append(
                    {
                        **item_info,
                        "status": "ğŸŸ¡ å†å²æ•°æ®ä¸è¶³ï¼ˆä»…{}å¤©ï¼‰".format(
                            len(result) if not result.empty else 0
                        ),
                        "technical_indicators_summary": [
                            "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—å®Œæ•´æŠ€æœ¯æŒ‡æ ‡"
                        ],
                        "raw_debug_data": {
                            "history_data": result
                            if not result.empty
                            else pd.DataFrame(),
                            "forward_indicators": {},
                        },
                        "signal_data": {},
                        "alert_data": {},
                    }
                )
                continue

            # å­—æ®µæ ‡å‡†åŒ–
            if "æ”¶ç›˜" in result.columns:
                result.rename(columns={"æ”¶ç›˜": "close"}, inplace=True)
            elif "close" not in result.columns and "Close" in result.columns:
                result.rename(columns={"Close": "close"}, inplace=True)

            if "æœ€é«˜" in result.columns:
                result.rename(columns={"æœ€é«˜": "high"}, inplace=True)
            elif "high" not in result.columns and "High" in result.columns:
                result.rename(columns={"High": "high"}, inplace=True)

            if "æœ€ä½" in result.columns:
                result.rename(columns={"æœ€ä½": "low"}, inplace=True)
            elif "low" not in result.columns and "Low" in result.columns:
                result.rename(columns={"Low": "low"}, inplace=True)

            if "æ—¥æœŸ" in result.columns:
                result["æ—¥æœŸ"] = pd.to_datetime(result["æ—¥æœŸ"])
                result.set_index("æ—¥æœŸ", inplace=True)
            elif "date" in result.columns:
                result["date"] = pd.to_datetime(result["date"])
                result.set_index("date", inplace=True)
            result.index.name = None

            # å®‰å…¨è½¬æ¢æ•°å€¼ç±»å‹ - å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ•°å€¼ç±»å‹
            def safe_to_numeric(series):
                """å®‰å…¨è½¬æ¢ä¸ºæ•°å€¼ç±»å‹"""
                try:
                    # å¦‚æœå·²ç»æ˜¯æ•°å€¼ç±»å‹ï¼Œç›´æ¥è¿”å›
                    if pd.api.types.is_numeric_dtype(series):
                        return series
                    # å¦åˆ™å°è¯•è½¬æ¢
                    return pd.to_numeric(series, errors="coerce")
                except:
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸåºåˆ—ï¼ˆåç»­ä¼šè·³è¿‡ï¼‰
                    return series

            try:
                if "close" in result.columns:
                    result["close"] = safe_to_numeric(result["close"])
                if "high" in result.columns:
                    result["high"] = safe_to_numeric(result["high"])
                if "low" in result.columns:
                    result["low"] = safe_to_numeric(result["low"])
            except Exception as e:
                logger.warning(f"âš ï¸ {name}({code}) æ•°å€¼è½¬æ¢å¼‚å¸¸: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œè®©åç»­ä»£ç å¤„ç†å¯èƒ½çš„NaNå€¼

            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„closeåˆ—
            if "close" not in result.columns:
                logger.info(f"âš ï¸ {name}({code})ï¼šç¼ºå°‘å¿…è¦çš„'close'åˆ—ï¼Œæ ‡è®°ä¸ºæ•°æ®ä¸è¶³")
                analysis_report.append(
                    {
                        **item_info,
                        "status": "ğŸŸ¡ æ•°æ®æ ¼å¼å¼‚å¸¸ï¼ˆç¼ºå°‘closeåˆ—ï¼‰",
                        "technical_indicators_summary": [
                            "æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•è¿›è¡ŒæŠ€æœ¯åˆ†æ"
                        ],
                        "raw_debug_data": {
                            "history_data": result,
                            "forward_indicators": {},
                        },
                        "signal_data": {},
                        "alert_data": {},
                    }
                )
                continue

            # æ£€æŸ¥closeåˆ—æ˜¯å¦å…¨ä¸ºç©º
            if result["close"].isnull().all():
                logger.info(f"âš ï¸ {name}({code})ï¼š'close'åˆ—æ•°æ®å…¨ä¸ºç©ºå€¼ï¼Œæ ‡è®°ä¸ºæ•°æ®ä¸è¶³")
                analysis_report.append(
                    {
                        **item_info,
                        "status": "ğŸŸ¡ æ•°æ®å¼‚å¸¸ï¼ˆcloseå€¼ä¸ºç©ºï¼‰",
                        "technical_indicators_summary": [
                            "æ”¶ç›˜ä»·æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡ŒæŠ€æœ¯åˆ†æ"
                        ],
                        "raw_debug_data": {
                            "history_data": result,
                            "forward_indicators": {},
                        },
                        "signal_data": {},
                        "alert_data": {},
                    }
                )
                continue

            # ä½¿ç”¨pandaså†…ç½®åŠŸèƒ½è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            result["SMA_5"] = result["close"].rolling(window=5).mean()
            result["SMA_10"] = result["close"].rolling(window=10).mean()
            result["SMA_20"] = result["close"].rolling(window=20).mean()
            result["SMA_60"] = result["close"].rolling(window=60).mean()

            # MACDè®¡ç®— - ä½¿ç”¨talibé£æ ¼ä»¥åŒ¹é…ä¸œæ–¹è´¢å¯Œ
            dif, dea, macd_bar = calculate_macd_for_eastmoney(result["close"])
            result["MACD_12_26_9"] = dif  # DIF
            result["MACDs_12_26_9"] = dea  # DEA (ä¿¡å·çº¿)
            result["MACDh_12_26_9"] = macd_bar  # MACDæŸ±ï¼ˆå·²Ã—2ï¼‰

            # ç®€åŒ–çš„å¸ƒæ—å¸¦è®¡ç®—
            result["BBM_20_2.0"] = result["close"].rolling(window=20).mean()
            std = result["close"].rolling(window=20).std()
            result["BBU_20_2.0"] = result["BBM_20_2.0"] + (std * 2)
            result["BBL_20_2.0"] = result["BBM_20_2.0"] - (std * 2)

            # è®¡ç®—å‰ç»æ€§æŠ€æœ¯æŒ‡æ ‡ï¼ˆRSIã€KDJã€CCIã€OBVã€å¨å»‰æŒ‡æ ‡ï¼‰
            result = calculate_forward_indicators(result)

            # æ·»åŠ æˆäº¤é‡åˆ—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if "volume" not in result.columns and "æˆäº¤é‡" in result.columns:
                result["volume"] = result["æˆäº¤é‡"]

            if len(result) < 2:
                logger.info(
                    f"è·³è¿‡ {name}({code})ï¼šå†å²æ•°æ®ä¸è¶³2å¤©ï¼ˆå®é™…{len(result)}å¤©ï¼‰"
                )
                continue
            latest = result.iloc[-1]
            prev_latest = result.iloc[-2]
            trend_signals = []

            # åˆ†æä¼ ç»ŸæŒ‡æ ‡
            analyze_ma(result, latest, prev_latest, trend_signals)
            analyze_macd(result, latest, prev_latest, trend_signals)
            analyze_bollinger(result, latest, prev_latest, trend_signals)

            # åˆ†æå‰ç»æ€§æŒ‡æ ‡
            try:
                analyze_rsi(result, latest, prev_latest, trend_signals)
                analyze_kdj(result, latest, prev_latest, trend_signals)
                analyze_cci(result, latest, prev_latest, trend_signals)
                analyze_obv(result, latest, prev_latest, trend_signals)
                analyze_williams(result, latest, prev_latest, trend_signals)
            except Exception as e:
                logger.warning(f"å‰ç»æ€§æŒ‡æ ‡åˆ†æå¤±è´¥: {e}")
                # ç»§ç»­æ‰§è¡Œï¼Œè®©åç»­ä»£ç å¤„ç†å¯èƒ½çš„NaNå€¼

            # --- çŠ¶æ€åˆ¤å®š ---
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å……è¶³ï¼Œå¦‚æœä¸è¶³61å¤©åˆ™æ ‡è®°ä¸ºæ•°æ®ä¸è¶³
            if len(result) < 61:
                status = f"ğŸŸ¡ å†å²æ•°æ®ä¸è¶³ï¼ˆä»…{len(result)}å¤©ï¼‰"
                # åœ¨æŠ€æœ¯æŒ‡æ ‡æ€»ç»“ä¸­æ·»åŠ æç¤º
                trend_signals.insert(
                    0, f"âš ï¸ å†å²æ•°æ®ä»…{len(result)}å¤©ï¼Œéƒ¨åˆ†æŒ‡æ ‡å¯èƒ½ä¸å‡†ç¡®"
                )
            else:
                status = judge_trend_status(latest, prev_latest)

            # --- é¢„æµ‹å’Œé¢„è­¦ç³»ç»Ÿ ---
            # ä¸å†ä½¿ç”¨ç®—æ³•é¢„æµ‹ç³»ç»Ÿï¼Œå®Œå…¨ä¾èµ–AIé¢„æµ‹
            # price_predictor = PricePredictorDebug()
            # prediction_data = price_predictor.predict_price(result, latest, None)
            prediction_data = {}  # ç©ºé¢„æµ‹æ•°æ®ï¼Œå®Œå…¨ä¾èµ–AI

            # åˆå§‹åŒ–é¢„è­¦ç³»ç»Ÿ
            alert_system = AlertSystem()

            # ç”Ÿæˆé¢„è­¦ä¿¡æ¯ï¼ˆä¸å†ä¾èµ–signal_dataï¼‰
            alert_data = alert_system.generate_alerts(result, latest, prev_latest, None)

            # ä¿¡å·ç³»ç»Ÿç”±AIå†³ç­–ï¼Œä¸å†ä½¿ç”¨è§„åˆ™ç³»ç»Ÿ
            signal_data = {}

            # åˆ†æå®Œæˆ

            analysis_report.append(
                {
                    **item_info,
                    "status": status,
                    "technical_indicators_summary": trend_signals,
                    "raw_debug_data": {
                        "history_data": result,  # ä¿å­˜å†å²æ•°æ®ç”¨äºåˆ›å»ºå®æ—¶æ•°æ®
                        "forward_indicators": {
                            "RSI_12": float(latest.get("RSI_12"))
                            if pd.notna(latest.get("RSI_12"))
                            else None,
                            "KDJ_K": float(latest.get("KDJ_K"))
                            if pd.notna(latest.get("KDJ_K"))
                            else None,
                            "KDJ_D": float(latest.get("KDJ_D"))
                            if pd.notna(latest.get("KDJ_D"))
                            else None,
                            "KDJ_J": float(latest.get("KDJ_J"))
                            if pd.notna(latest.get("KDJ_J"))
                            else None,
                            "CCI_14": float(latest.get("CCI_14"))
                            if pd.notna(latest.get("CCI_14"))
                            else None,
                            "OBV": float(latest.get("OBV"))
                            if pd.notna(latest.get("OBV"))
                            else None,
                            "OBV_change": float(
                                latest.get("OBV", 0) - prev_latest.get("OBV", 0)
                            )
                            if pd.notna(latest.get("OBV"))
                            and pd.notna(prev_latest.get("OBV"))
                            else None,
                            "OBV_debug": f"latest={latest.get('OBV'):.2f}, prev={prev_latest.get('OBV'):.2f}, change={latest.get('OBV', 0) - prev_latest.get('OBV', 0):.2f}"
                            if pd.notna(latest.get("OBV"))
                            and pd.notna(prev_latest.get("OBV"))
                            else "OBVæ•°æ®ç¼ºå¤±",
                            "WR1": float(latest.get("WR1"))
                            if pd.notna(latest.get("WR1"))
                            else None,
                            "WR2": float(latest.get("WR2"))
                            if pd.notna(latest.get("WR2"))
                            else None,
                        },
                    },
                    "signal_data": signal_data,  # ä¹°å–ä¿¡å·æ•°æ®
                    # "prediction_data": prediction_data,  # ä¸åŒ…å«ç®—æ³•é¢„æµ‹æ•°æ®
                    "alert_data": alert_data,  # é¢„è­¦æ•°æ®
                }
            )
        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè·³è¿‡ä¸å†™å…¥åˆ†æç»“æœï¼Œåªè®°å½•æ—¥å¿—
            error_type = str(e)
            import traceback

            logger.error(f"åˆ†æ {name}({code}) æ—¶å‡ºç°é”™è¯¯: {type(e).__name__}: {e}")
            logger.error(f"é”™è¯¯è¿½è¸ª:\n{traceback.format_exc()}")
            if (
                "RetryError" in error_type
                or "ConnectionError" in error_type
                or "RemoteDisconnected" in error_type
            ):
                logger.info(f"è·³è¿‡ {name}({code})ï¼šç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ•°æ®è·å–å¤±è´¥")
            elif "Timeout" in error_type:
                logger.info(f"è·³è¿‡ {name}({code})ï¼šæ•°æ®è·å–è¶…æ—¶")
            else:
                logger.info(
                    f"è·³è¿‡ {name}({code})ï¼šåˆ†æè¿‡ç¨‹å‡ºé”™ - {type(e).__name__}: {e}"
                )
            # ä¸å†™å…¥é”™è¯¯æŠ¥å‘Šï¼Œç›´æ¥è·³è¿‡
            continue
    return analysis_report


class _IntradaySignalGenerator:
    def __init__(self, item_list, item_type):
        self.item_list = item_list
        self.item_type = item_type

    def generate_signals(self, all_item_data_df):
        results = []
        # å¦‚æœæ•°æ®æ¡†ä¸ºç©ºï¼Œä¸ºæ‰€æœ‰æ ‡çš„åˆ›å»ºåŸºç¡€ä¿¡å·
        if all_item_data_df is None or all_item_data_df.empty:
            logger.warning("å®æ—¶æ•°æ®ä¸ºç©ºï¼Œä¸ºæ‰€æœ‰æ ‡çš„åˆ›å»ºåŸºç¡€ä¿¡å·")
            for item in self.item_list:
                results.append(
                    {
                        "code": item.get("code", ""),
                        "name": item.get("name", "æœªçŸ¥"),
                        "price": None,
                        "change": 0,
                        "æ¶¨è·Œå¹…": 0,
                        "analysis_points": ["å®æ—¶æ•°æ®è·å–å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ—¥å†…ä¿¡å·åˆ†æ"],
                    }
                )
            return results

        # æ£€æŸ¥æ•°æ®æ¡†æ˜¯å¦æœ‰å¿…è¦çš„åˆ—
        if "ä»£ç " not in all_item_data_df.columns:
            logger.warning("å®æ—¶æ•°æ®ç¼ºå°‘'ä»£ç 'åˆ—ï¼Œä¸ºæ‰€æœ‰æ ‡çš„åˆ›å»ºåŸºç¡€ä¿¡å·")
            for item in self.item_list:
                results.append(
                    {
                        "code": item.get("code", ""),
                        "name": item.get("name", "æœªçŸ¥"),
                        "price": None,
                        "change": 0,
                        "æ¶¨è·Œå¹…": 0,
                        "analysis_points": ["å®æ—¶æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ— æ³•è¿›è¡Œæ—¥å†…ä¿¡å·åˆ†æ"],
                    }
                )
            return results

        # æ­£å¸¸å¤„ç†ï¼šä¸ºæ¯ä¸ªæ ‡çš„ç”Ÿæˆä¿¡å·
        for item in self.item_list:
            code = item.get("code", "")
            name = item.get("name", "æœªçŸ¥")

            try:
                # æ›´çµæ´»çš„ä»£ç åŒ¹é…ï¼šå¤„ç†å­—ç¬¦ä¸²å’Œæ•°å­—æ ¼å¼
                item_data_row = None

                # å…ˆå°†codeè½¬ä¸ºå­—ç¬¦ä¸²
                code_str = str(code)

                # å°è¯•ç²¾ç¡®åŒ¹é…
                item_data_row = all_item_data_df[all_item_data_df["ä»£ç "] == code]

                # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•å­—ç¬¦ä¸²åŒ¹é…
                if item_data_row.empty:
                    item_data_row = all_item_data_df[
                        all_item_data_df["ä»£ç "].astype(str) == code_str
                    ]

                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«å…³ç³»
                if item_data_row.empty and len(code_str) >= 4:
                    # æŸ¥æ‰¾ä»£ç å‰å‡ ä½åŒ¹é…çš„
                    mask = (
                        all_item_data_df["ä»£ç "]
                        .astype(str)
                        .str.startswith(code_str[:4])
                    )
                    if mask.any():
                        item_data_row = all_item_data_df[mask]
                        if len(item_data_row) > 1:
                            # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œå–ç¬¬ä¸€ä¸ª
                            logger.info(
                                f"æ‰¾åˆ°å¤šä¸ªåŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª: {item_data_row['ä»£ç '].tolist()}"
                            )
                        item_data_row = item_data_row.head(1)

                if not item_data_row.empty:
                    current_data = item_data_row.iloc[0]
                    results.append(self._create_signal_dict(current_data, item))
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°è¯¥æ ‡çš„çš„æ•°æ®ï¼Œåˆ›å»ºåŸºç¡€ä¿¡å·
                    logger.warning(
                        f"æ ‡çš„ {name}({code}) åœ¨å®æ—¶æ•°æ®ä¸­æœªæ‰¾åˆ°ï¼Œåˆ›å»ºåŸºç¡€ä¿¡å·"
                    )
                    results.append(
                        {
                            "code": code,
                            "name": name,
                            "price": None,
                            "change": 0,
                            "æ¶¨è·Œå¹…": 0,
                            "analysis_points": [
                                "å®æ—¶æ•°æ®ä¸­æœªæ‰¾åˆ°è¯¥æ ‡çš„ï¼Œæ— æ³•è¿›è¡Œæ—¥å†…ä¿¡å·åˆ†æ"
                            ],
                        }
                    )
            except Exception as e:
                # å¦‚æœå¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œåˆ›å»ºé”™è¯¯ä¿¡å·
                logger.error(f"å¤„ç†æ ‡çš„ {name}({code}) ä¿¡å·æ—¶å‡ºé”™: {e}")
                results.append(
                    {
                        "code": code,
                        "name": name,
                        "price": None,
                        "change": 0,
                        "æ¶¨è·Œå¹…": 0,
                        "analysis_points": [f"ä¿¡å·ç”Ÿæˆå¤±è´¥: {str(e)[:100]}"],
                    }
                )

        return results

    def _create_signal_dict(self, item_series, item_info):
        points = []
        code = item_series.get("ä»£ç ")
        raw_change = item_series.get("æ¶¨è·Œå¹…", 0)
        # æ ¹æ®æ ‡çš„ç±»å‹å¤„ç†æ¶¨è·Œå¹…
        # æ¶¨è·Œå¹…ç»Ÿä¸€å¤„ç†ï¼šç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
        change = raw_change
        if change > 2.5:
            points.append("æ—¥å†…å¤§å¹…ä¸Šæ¶¨")
        if change < -2.5:
            points.append("æ—¥å†…å¤§å¹…ä¸‹è·Œ")
        return {
            "code": code,
            "name": item_info.get("name"),
            "price": item_series.get("æœ€æ–°ä»·"),
            "change": change,
            "æ¶¨è·Œå¹…": change,  # æ·»åŠ æ¶¨è·Œå¹…å­—æ®µï¼Œä¸å‰ç«¯ä¿æŒä¸€è‡´
            "analysis_points": points if points else ["ç›˜ä¸­ä¿¡å·å¹³ç¨³"],
        }


async def get_detailed_analysis_report_for_debug(
    get_realtime_data_func, get_daily_history_func, core_pool
):
    logger.info("å¯åŠ¨AIé©±åŠ¨çš„è°ƒè¯•åˆ†æå¼•æ“ï¼Œä¸è°ƒç”¨LLM...")
    realtime_data_df_task = asyncio.to_thread(get_realtime_data_func)
    daily_trends_task = _get_daily_trends_generic(get_daily_history_func, core_pool)
    realtime_data_df, daily_trends_list = await asyncio.gather(
        realtime_data_df_task, daily_trends_task
    )
    if realtime_data_df is None:
        return [
            {"name": "é”™è¯¯", "code": "", "ai_comment": "è·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œæ— æ³•åˆ†æã€‚"}
        ]
    daily_trends_map = {item["code"]: item for item in daily_trends_list}
    if get_realtime_data_func == get_all_stock_spot_realtime:
        item_type = "stock"
    else:
        item_type = "etf"
    intraday_analyzer = _IntradaySignalGenerator(core_pool, item_type=item_type)
    intraday_signals = intraday_analyzer.generate_signals(realtime_data_df)
    debug_report = []
    for i, signal in enumerate(intraday_signals):
        code = signal["code"]
        name = signal["name"]
        logger.info(f"æ­£åœ¨å‡†å¤‡è°ƒè¯•æŠ¥å‘Š: {name} ({i + 1}/{len(intraday_signals)})")
        daily_trend_info = daily_trends_map.get(
            code,
            {
                "status": "æœªçŸ¥",
                "technical_indicators_summary": [],
                "raw_debug_data": {},
            },
        )
        raw_debug_data = daily_trend_info.get("raw_debug_data", {})
        if not raw_debug_data:
            raw_debug_data = {}
        debug_report.append(
            {
                "code": code,
                "name": name,
                "price": signal.get("price"),
                "change": signal.get("change"),
                "intraday_signals": signal.get("analysis_points"),
                "daily_trend_status": daily_trend_info.get("status"),
                "technical_indicators_summary": daily_trend_info.get(
                    "technical_indicators_summary"
                ),
                "raw_debug_data": raw_debug_data,
            }
        )
        await asyncio.sleep(random.uniform(0.5, 1.0))
    return debug_report
