# llm_analyzer.py (ä¼˜åŒ– prompt_data å’Œ system_prompt)

import os
import json
import logging
import asyncio
from openai import OpenAI

logger = logging.getLogger(__name__)

# --- é…ç½® ---
def _get_api_provider():
    """æ£€æµ‹APIæä¾›å•†ç±»å‹"""
    api_base = os.getenv("LLM_API_BASE", "").lower()
    if "perplexity" in api_base:
        return "perplexity"
    elif "openai" in api_base or "siliconflow" in api_base:
        return "openai"
    else:
        return "openai"  # é»˜è®¤ä¸ºOpenAIæ ¼å¼

def _get_openai_client():
    """åŠ¨æ€è·å–OpenAIå®¢æˆ·ç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„é…ç½®"""
    try:
        api_base = os.getenv("LLM_API_BASE")
        api_key = os.getenv("LLM_API_KEY")
        
        if not api_base or not api_key:
            logger.warning("LLM APIé…ç½®ä¸å®Œæ•´ï¼Œè¯·åœ¨Webç•Œé¢é…ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡")
            return None
            
        return OpenAI(
            base_url=api_base,
            api_key=api_key,
        )
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None

# å…¨å±€å®¢æˆ·ç«¯å˜é‡
client = None

# --- æ ¸å¿ƒå‡½æ•° ---
async def get_llm_score_and_analysis(etf_data, daily_trend_data):
    """è°ƒç”¨å¤§æ¨¡å‹å¯¹å•æ”¯ETFè¿›è¡Œåˆ†æå’Œæ‰“åˆ†"""
    # åŠ¨æ€è·å–å®¢æˆ·ç«¯
    current_client = _get_openai_client()
    if current_client is None:
        return None, "LLMæœåŠ¡æœªé…ç½®æˆ–åˆå§‹åŒ–å¤±è´¥ã€‚è¯·åœ¨é…ç½®é¡µé¢è®¾ç½®AIæ¨¡å‹å‚æ•°ã€‚"
    
    # æ£€æµ‹APIæä¾›å•†
    api_provider = _get_api_provider()
    logger.info(f"æ£€æµ‹åˆ°APIæä¾›å•†: {api_provider}")
        
    # --- 1. ä¿®æ”¹ prompt_data çš„ç»“æ„ ---
    # å°†æ‰€æœ‰å¿…è¦çš„ä¿¡æ¯éƒ½æ‰å¹³åŒ–ï¼Œç›´æ¥ä¼ é€’ç»™LLM
    # LLMä¼šçœ‹åˆ° etf_data å’Œ daily_trend_data ç»„åˆåœ¨ä¸€èµ·çš„å®Œæ•´ä¿¡æ¯
    combined_data = {
        "æŠ•èµ„æ ‡çš„åç§°": etf_data.get('name'),
        "ä»£ç ": etf_data.get('code'),
        "æ—¥å†…æ¶¨è·Œå¹…": f"{etf_data.get('change', 0):.2f}%",
        "æ—¥çº¿çº§åˆ«æ•´ä½“è¶‹åŠ¿": daily_trend_data.get('status'), # ä¾‹å¦‚ 'ğŸŸ¢ å¼ºåŠ¿ä¸Šå‡è¶‹åŠ¿'
        "ç›˜ä¸­æŠ€æœ¯ä¿¡å·": daily_trend_data.get('intraday_signals'), # è¿™ä¸ªdaily_trend_dataä¸­æ²¡æœ‰ï¼Œåº”è¯¥æ˜¯etf_dataé‡Œ
        "è¯¦ç»†æŠ€æœ¯æŒ‡æ ‡åˆ†æåˆ—è¡¨": daily_trend_data.get('technical_indicators_summary', []) # è¿™æ˜¯å…³é”®ï¼Œä¼ é€’è¯¦ç»†çš„åˆ—è¡¨
    }
    # ä¿®æ­£ï¼šintraday_signalsåº”è¯¥ä»etf_dataè·å–
    if etf_data.get('analysis_points'):
        combined_data["ç›˜ä¸­æŠ€æœ¯ä¿¡å·"] = etf_data.get('analysis_points')
    else:
        combined_data["ç›˜ä¸­æŠ€æœ¯ä¿¡å·"] = [] # ç¡®ä¿å§‹ç»ˆæ˜¯åˆ—è¡¨

    # --- 2. ä¼˜åŒ– system_prompt ---
    # æ˜ç¡®æŒ‡ç¤ºLLMå¦‚ä½•åˆ©ç”¨ 'è¯¦ç»†æŠ€æœ¯æŒ‡æ ‡åˆ†æåˆ—è¡¨'ï¼Œå¹¶è¦æ±‚è¾“å‡ºä¸ºä¸€æ®µè‡ªç„¶è¯­è¨€çš„ç‚¹è¯„å­—ç¬¦ä¸²
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èæ•°æ®åˆ†æå¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„JSONæ•°æ®ï¼Œè¿›è¡Œå…¨é¢ã€å®¢è§‚çš„æŠ•èµ„æ ‡çš„åˆ†æã€‚\n"
        "åˆ†æå†…å®¹åŒ…æ‹¬ï¼š\n"
        "1. **æ¦‚è§ˆ**ï¼šæŠ•èµ„æ ‡çš„åç§°ã€ä»£ç ã€æ—¥å†…æ¶¨è·Œå¹…ã€‚\n"
        "2. **å®è§‚è¶‹åŠ¿**ï¼šæ—¥çº¿çº§åˆ«æ•´ä½“è¶‹åŠ¿ã€‚\n"
        "3. **å³æ—¶ä¿¡å·**ï¼šç›˜ä¸­æŠ€æœ¯ä¿¡å·ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚\n"
        "4. **è¯¦ç»†æŠ€æœ¯é¢**ï¼šæ ¹æ®æä¾›çš„'è¯¦ç»†æŠ€æœ¯æŒ‡æ ‡åˆ†æåˆ—è¡¨'ï¼Œå¯¹å‡çº¿ã€å¸ƒæ—é€šé“ä½ç½®ã€MACDç­‰è¿›è¡Œç»¼åˆåˆ†æï¼Œ\n"
        "   - **åŠ¡å¿…æåŠåˆ—è¡¨ä¸­çš„æ¯ä¸€é¡¹æŒ‡æ ‡ï¼ˆå³ä½¿æ˜¯æ•°æ®ç¼ºå¤±æˆ–ä¸­æ€§ä¿¡å·ï¼‰ï¼Œå¹¶ç”¨æ¸…æ™°çš„è‡ªç„¶è¯­è¨€æè¿°å…¶å«ä¹‰**ã€‚\n"
        "   - ä¾‹å¦‚ï¼š'è‚¡ä»·é«˜äº20æ—¥å‡çº¿ï¼ŒçŸ­æœŸè¶‹åŠ¿å‘ä¸Šï¼›MACDé‡‘å‰ï¼Œå¤šå¤´åŠ›é‡å¢å¼ºï¼›æˆäº¤é‡è¾ƒ60æ—¥å‡é‡æ˜¾è‘—æ”¾å¤§ï¼Œå¸‚åœºæ´»è·ƒã€‚'\n"
        "   - **é¿å…ç›´æ¥å¼•ç”¨åˆ—è¡¨ä¸­çš„åŸå¥ï¼Œè€Œæ˜¯æ•´åˆä¸ºè¿è´¯çš„åˆ†ææ€§è¯­å¥**ã€‚\n"
        "5. **ç»¼åˆè¯„åˆ†å’Œç²¾ç‚¼ç‚¹è¯„**ï¼š\n"
        "   - ç»¼åˆä¸Šè¿°åˆ†æï¼Œç»™å‡ºä¸€ä¸ª0-100åˆ†çš„ç»¼åˆè¯„åˆ†ï¼ˆ50ä¸ºä¸­æ€§ï¼‰ã€‚\n"
        "   - æ’°å†™ä¸€å¥ç²¾ç‚¼çš„äº¤æ˜“ç‚¹è¯„ï¼ˆä½œä¸ºcommentå­—æ®µå†…å®¹ï¼‰ã€‚\n"
        "   - **ç‚¹è¯„åº”æ˜¯æµç•…çš„è‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯åµŒå¥—çš„JSONæˆ–å­—å…¸**ã€‚\n\n"
        "è¯·ä¸¥æ ¼ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«'score'ï¼ˆæ•°å­—ç±»å‹ï¼‰å’Œ'comment'ï¼ˆå­—ç¬¦ä¸²ç±»å‹ï¼‰ä¸¤ä¸ªé”®ï¼Œä¾‹å¦‚:\n"
        '{"score": 75, "comment": "ä¸Šè¯50ETFç›®å‰æŠ€æœ¯é¢è¡¨ç°å¼ºåŠ²ï¼Œè‚¡ä»·ç«™ä¸Šå¤šæ¡å‡çº¿ï¼ŒMACDå‘ˆé‡‘å‰ï¼Œä½†éœ€æ³¨æ„é‡èƒ½æ˜¯å¦æŒç»­ã€‚å»ºè®®å…³æ³¨ã€‚"} \n'
        "ç¡®ä¿commentå­—æ®µæ˜¯**çº¯å­—ç¬¦ä¸²**ï¼Œä¸åŒ…å«ä»»ä½•åµŒå¥—JSONç»“æ„ã€‚" # å†æ¬¡å¼ºè°ƒ
    )

    try:
        # æ ¹æ®APIæä¾›å•†æ„å»ºä¸åŒçš„è¯·æ±‚å‚æ•°
        request_params = {
            "model": os.getenv("LLM_MODEL_NAME", "sonar-pro"),
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": json.dumps(combined_data, ensure_ascii=False, indent=2)}
            ]
        }
        
        # æ ¹æ®APIæä¾›å•†æ·»åŠ ä¸åŒçš„å‚æ•°
        if api_provider == "perplexity":
            # Perplexity AI ç‰¹æ®Šå¤„ç†
            request_params.update({
                "max_tokens": 1000,
                "temperature": 0.7,
                "top_p": 0.9
            })
            logger.info("ä½¿ç”¨Perplexity AIæ ¼å¼è¯·æ±‚")
        else:
            # OpenAI å…¼å®¹æ ¼å¼
            request_params.update({
                "response_format": {
                    "type": "json_schema",
                    "json_schema": {
                        "schema": {
                            "type": "object",
                            "properties": {
                                "score": {"type": "number", "description": "0åˆ°100åˆ†çš„ç»¼åˆè¯„åˆ†"},
                                "comment": {"type": "string", "description": "ä¸€æ®µæµç•…çš„ã€æ€»ç»“æ€§çš„è‡ªç„¶è¯­è¨€äº¤æ˜“ç‚¹è¯„"}
                            },
                            "required": ["score", "comment"]
                        }
                    }
                }
            })
            logger.info("ä½¿ç”¨OpenAIå…¼å®¹æ ¼å¼è¯·æ±‚")
        
        response = await asyncio.to_thread(
            current_client.chat.completions.create,
            **request_params
        )
        
        raw_content = response.choices[0].message.content
        if not raw_content:
            logger.warning(f"LLMä¸ºç©ºå†…å®¹è¿”å›: {etf_data.get('name')}")
            return 50, "æ¨¡å‹æœªæä¾›æœ‰æ•ˆåˆ†æã€‚"

        # æ ¹æ®APIæä¾›å•†è¿›è¡Œä¸åŒçš„è§£æ
        if api_provider == "perplexity":
            # Perplexity AI ç‰¹æ®Šè§£æï¼šä»æ–‡æœ¬ä¸­æå–JSON
            score, comment = _parse_perplexity_response(raw_content)
        else:
            # OpenAI å…¼å®¹æ ¼å¼è§£æ
            score, comment = _parse_openai_response(raw_content)
        
        return score, comment

    except Exception as e:
        logger.error(f"è°ƒç”¨æˆ–è§£æLLMå“åº”æ—¶å‡ºé”™: {e}", exc_info=True)
        return 50, f"LLMåˆ†ææœåŠ¡å¼‚å¸¸: {e}" # è¿”å›50åˆ†å’Œé”™è¯¯ä¿¡æ¯ï¼Œç¡®ä¿ç¨‹åºä¸å´©æºƒ

def _parse_perplexity_response(raw_content):
    """è§£æPerplexity AIçš„å“åº”"""
    import re
    
    try:
        # å°è¯•ç›´æ¥è§£æJSON
        parsed_json = json.loads(raw_content)
        if isinstance(parsed_json, dict):
            score = parsed_json.get('score', 50)
            comment = parsed_json.get('comment', 'Perplexity AIåˆ†æå®Œæˆ')
            return float(score) if isinstance(score, (int, float)) else 50, str(comment)
    except json.JSONDecodeError:
        pass
    
    # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–JSON
    try:
        # æŸ¥æ‰¾JSONæ¨¡å¼
        json_pattern = r'\{[^{}]*"score"[^{}]*"comment"[^{}]*\}'
        json_match = re.search(json_pattern, raw_content, re.DOTALL)
        
        if json_match:
            json_str = json_match.group(0)
            parsed_json = json.loads(json_str)
            score = parsed_json.get('score', 50)
            comment = parsed_json.get('comment', 'Perplexity AIåˆ†æå®Œæˆ')
            return float(score) if isinstance(score, (int, float)) else 50, str(comment)
    except (json.JSONDecodeError, AttributeError):
        pass
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œå°è¯•æå–æ•°å­—è¯„åˆ†
    try:
        # æŸ¥æ‰¾è¯„åˆ†æ•°å­—
        score_pattern = r'"score":\s*(\d+(?:\.\d+)?)'
        score_match = re.search(score_pattern, raw_content)
        score = float(score_match.group(1)) if score_match else 50
        
        # æŸ¥æ‰¾è¯„è®ºå†…å®¹
        comment_pattern = r'"comment":\s*"([^"]*)"'
        comment_match = re.search(comment_pattern, raw_content)
        comment = comment_match.group(1) if comment_match else "Perplexity AIåˆ†æå®Œæˆ"
        
        return score, comment
    except (AttributeError, ValueError):
        pass
    
    # æœ€åçš„å…œåº•æ–¹æ¡ˆ
    logger.warning(f"Perplexity AIå“åº”è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {raw_content[:200]}...")
    return 50, "Perplexity AIåˆ†æå®Œæˆï¼Œä½†å“åº”æ ¼å¼éœ€è¦ä¼˜åŒ–"

def _parse_openai_response(raw_content):
    """è§£æOpenAIå…¼å®¹æ ¼å¼çš„å“åº”"""
    try:
        parsed_json = json.loads(raw_content)
        
        # ç¡®ä¿è§£æç»“æœæ˜¯å­—å…¸
        result_dict = None
        if isinstance(parsed_json, list) and parsed_json:
            result_dict = parsed_json[0]
        elif isinstance(parsed_json, dict):
            result_dict = parsed_json

        if result_dict and isinstance(result_dict, dict):
            score = result_dict.get('score')
            comment = result_dict.get('comment')
            if not isinstance(score, (int, float)):
                score = 50
            return float(score), str(comment)
        else:
            logger.error(f"OpenAIè¿”å›æ ¼å¼é”™è¯¯ï¼Œä¸æ˜¯é¢„æœŸçš„JSONå­—å…¸: {raw_content}")
            return 50, "OpenAIè¿”å›æ ¼å¼é”™è¯¯æˆ–å†…å®¹ä¸ç¬¦åˆé¢„æœŸã€‚"
    except json.JSONDecodeError as e:
        logger.error(f"OpenAIå“åº”JSONè§£æå¤±è´¥: {e}, å†…å®¹: {raw_content}")
        return 50, "OpenAIå“åº”è§£æå¤±è´¥"
